<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>菜叶</title>
  
  <subtitle>快乐、奋斗、加油</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://leaveslr.github.io/"/>
  <updated>2018-02-05T06:32:19.477Z</updated>
  <id>https://leaveslr.github.io/</id>
  
  <author>
    <name>刘荣</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Adaptive, Personalized Diversity for Visual Discovery</title>
    <link href="https://leaveslr.github.io/2018/02/05/Adaptive-Personalized-Diversity-for-Visual-Discovery/"/>
    <id>https://leaveslr.github.io/2018/02/05/Adaptive-Personalized-Diversity-for-Visual-Discovery/</id>
    <published>2018-02-05T05:25:09.000Z</published>
    <updated>2018-02-05T06:32:19.477Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章来自 <a href="http://weibo.com/ttarticle/p/show?id=2309404022330610299674" target="_blank" rel="noopener">洪亮勋博客分享</a>,<a href="http://dl.acm.org/citation.cfm?id=2959171" target="_blank" rel="noopener">Adaptive, Personalized Diversity for Visual Discovery</a>文章为RecSys 2016的文章。</p><p>这篇文章解决的问题： - 基于贝叶斯回归模型的评分模型 - 基于主题的多样性模型子模块 - 基于用户的个性化多样性模型</p><h2 id="scoring-item-relevance">SCORING ITEM RELEVANCE</h2><p><span class="math display">\[P(click|item is viewed) = f(\sum_{x_i is active}{x_i})\]</span> 本文利用Thompson sampling <a href="http://www.research.rutgers.edu/~lihong/pub/Chapelle12Empirical.pdf" target="_blank" rel="noopener">an empirical evaluation of thompson sampling</a>，摘录了具体的实现 #### Regularized logistic regression with batch updates Require Regualization parameter <code>$\lambda&gt;0$</code></p><ul><li><span class="math inline">\(m_i=0,q_i=\lambda\)</span>,{Each wi has an independent prior <span class="math inline">\(N(m_i,q^{-1}_i)\)</span>}</li><li>for t = 1,…T do<ul><li>get new batch of training data (<span class="math inline">\(x_j,y_j\)</span>),j=1,..n</li><li>find w as the minimizer of :`<span class="math inline">\(\frac{1}{2} \sum^d_{i=1}{q_i(w_i-m_i)^2} + \sum^n_{j=1}{log(1+exp(-y_jw^Tx_j))}\)</span></li><li><span class="math inline">\(m_i=w_i\)</span></li><li><span class="math inline">\(q_i=q_i + \sum^n_{j=1}{x^2_{ij}p_j(1-p_j)},p_j=(1+exp(-w^Tx_j))^{-1}\)</span>{Laplace approximation}</li></ul></li><li>end for</li><li></li></ul><h2 id="submodular-diversification">submodular diversification</h2><p>submodelar 资料<a href="http://theory.stanford.edu/~jvondrak/data/submod-tutorial-1.pdf" target="_blank" rel="noopener">satnford cs</a>,详细的sumbmodular原理没有看懂，有时间再了解。</p><p>本文的方法，定义<span class="math inline">\(A:={a_1,..,a_n}\)</span>为推荐n个item的一些属性（主题）集合。其中属性集合为one-hot编码<span class="math inline">\(a_i\in\{0,1\}^d\)</span>.假设我们从n个集合中选取k个子集。 <span class="math display">\[p(A_k,w)=&lt;w,log(1+ \sum_{a_i\in{A_k}})&gt; + \sum_{a_i\in{A_k}}{s(a_i)}\]</span> 其中，<span class="math inline">\(s(a_i)\)</span>是item a的点击率预测（表征属性的质量或点击的概率），</p><p>有了以上的定义，选取对应最大的集合： <span class="math display">\[A^*_k := argmax_{A_k\in{A},|A_k|=k}{p(A_k,w)}\]</span></p><p><span class="math display">\[A_0:=0 and A_{i+1} := A_i \cup\{argmax_{a\in{A/A_i}}{p((A_i \cap {a},w))} \}\]</span></p><h2 id="personalization">personalization</h2><h3 id="learning-adaptive-global-weights">learning adaptive global weights</h3><p>文章对比了logistic regression、clicks over expected clicks,click-thru-rate with additive smoothing三种方法，实验效果差不多。所以试验中使用的基于平滑的CTR。</p><p><span class="math display">\[w_j = \frac{c_j+\alpha}{v_j+\alpha+\beta}\]</span> 其中，<span class="math inline">\(c_j,v_j\)</span>分别为类别j的点击和曝光量。</p><h3 id="user-specific-weights">user specific weights</h3><h4 id="user-modeling">user modeling</h4><p><span class="math display">\[w_u = (c_u + \alpha_0)||c_u+\alpha_0||^{-1}_1\]</span> 其中，<span class="math inline">\(c_u=\{c_{u1},..,c_{ud}\}\)</span>为用户u在不同主题上的点击数。<span class="math inline">\(alpha_0\)</span>的设置（can be chosen to math pre-specified business rules or to highlight certain category preferences）,不是特别懂。 #### user click singnal diffusion 这里主要是利用先验知识，如喜欢看游戏的主题，也喜欢看军事主题。所以加入主题的相似度矩阵（类似cf的 item-cf）。 <span class="math display">\[w_u = M w_u ||Mw_u||^{-1}_1\]</span> 其中，<span class="math inline">\(M_{ij} = \frac{cout(i,j)}{count(j)}\)</span>,cout(i,j)为同时看主题i,j的用户数 ，cout(j)为看主题j的用户数。M可以看做利用共现主题对w的平滑。</p><h2 id="结论">结论</h2><p>本文有用的几个结论： - 用户对于主题的多样性比较敏感。 -</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这篇文章来自 &lt;a href=&quot;http://weibo.com/ttarticle/p/show?id=2309404022330610299674&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;洪亮勋博客分享&lt;/a&gt;,&lt;a href=&quot;http://d
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://leaveslr.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>hexo中编辑数学公式</title>
    <link href="https://leaveslr.github.io/2018/02/03/math-formate-in-hexo/"/>
    <id>https://leaveslr.github.io/2018/02/03/math-formate-in-hexo/</id>
    <published>2018-02-03T14:28:15.000Z</published>
    <updated>2018-02-05T06:27:24.186Z</updated>
    
    <content type="html"><![CDATA[hexo中使用数学公式的一个简单介绍（非教程），全当记录自己的想法，等自己探索差不多后会沉淀成教程。 <a id="more"></a><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><h1 id="背景">背景</h1><p>这几天使用hexo搭建了自己的博客，在设定了一些个性化的配置后，就开始写自己的博客了，是不是很开心？然而我第一篇文章中就遇到问题了，怎么在博文中插入数学公式，并且本地编辑的时候能够可视化查看。基于这个问题，在网上查了半天终于搞定了。首先定义一下我们要解决的问题：</p><ol type="1"><li>hexo博文中能够加入数学公式并能完整显示（基于markdown）。</li><li>编辑本地markdown，并能可视化查看。</li></ol><h1 id="hexo工作原理">hexo工作原理</h1><p>其实下面讲了一通，在服务端可视化只要在hexo的配置中打开MathJax的开关就行了，同时对于marked中转义字符的问题参考<a href="http://shomy.top/2016/10/22/hexo-markdown-mathjax/" target="_blank" rel="noopener">Hexo下mathjax的转义问题</a>解决，想了解原理的可以继续看。</p><p>在开始讲解解决方案前，我们需要先了解一下hexo的工作原理，既hexo是如何通过我们编辑的makrdown文件生成一个漂亮的博客网站的。在<a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">官网</a>中如是描述hexo： &gt; Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p><p>换言之hexo是一个生成器或转换器，首先将source下的makrdown文件转换为可视化的html文件，然后根据我们的主题和相应的配置，渲染和组织博客，摘自<a href="http://coderunthings.com/2017/08/20/howhexoworks/" target="_blank" rel="noopener">hexo是怎么工作的</a>：</p><hr><p>简单来说，hexo中，从markdown到html的generate过程中做了两件事：模板渲染+模板渲染。如图所示 <img src="http://coderunthings.com/images/howhexoworks/render.png"> 对应的source下文件 <img src="http://coderunthings.com/images/howhexoworks/post.png"> 对上面表格和图的说明:</p><ul><li>hexo core在generate的过程中会产生一个对象，我们在这里把这个对象称为article。第一次渲染的主要目的就是给这个对象添加title,content等属性。其中:<ol type="1"><li>article.title, article.date, article.tags, article.categories等属性来自yml front的部分</li><li>article.content是markdown文章解析后的html片段</li></ol></li><li>hexo项目目录下包含三个子目录，<ol type="1"><li>source目录，写博客的主要工作目录。这个目录下存放的是我们的markdown文章以及js, images, css</li><li>themes目录，主题目录，定义了即将生成的html的layout, 和html中需要加载的css, js, images</li><li>ublic目录, hexo generate的最终输出目录。里面包含了整个博客网站的html, css, js, images</li></ol></li><li>第二次渲染，需要引入对应模板文件格式的插件，如.ejs文件就需要使用hexo-render-ejs插件，.jade文件需要使用hexo-render-jade插件，而.sass文件则需要hexo-render-sass插件来转换成css文件。hexo的这一设计有点类似webpack中的loader.`</li></ul><hr><p>通过以上的介绍，大家对hexo的原理应该很清楚了。我们所关心的在文中插入数学公式，只要在在将markdown文件转换为html时，转换器识别其中的数学公式符号并有对应的渲染器渲染数学公式就OK了。因此，第一个问题转换为： 1. 转换器识别markdown数学公式符号 2. html中能够渲染数学公式</p><p>对于转换器(解析器)hexo中使用的是<a href="https://github.com/hexojs/hexo-renderer-marked" target="_blank" rel="noopener">hexo-renderer-marked</a>，将标准的markdown转换为html格式文件。对于网页中公式的渲染使用的是MathJax,在hexo的配置文件中可以设置开启，这样生成的网页就会加上对应Mathjax配置。简单认识下这个两个工具</p><h2 id="marked">marked</h2><p><a href="https://github.com/chjj/marked" target="_blank" rel="noopener">marked</a>:marked是一个基于Nodejs的Markdown解析引擎。Markdown不是HTML，目前还不能被浏览器解析，所以需要Markdown的解析器如marked，把Markdown翻译成浏览器认识的HTML文档。举个栗子，下文是一个markdown的文章，通过marked转换为html格式。</p><pre><code>Marked Demo======================这是一个Marked库使用的例子。 http://blog.fens.me/nodejs-markdown-marked/&gt; A full-featured markdown parser and compiler, written in JavaScript. Built&gt; for speed.[![NPM version](https://badge.fury.io/js/marked.png)][badge]## Install<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install marked --save</span><br></pre></td></tr></table></figure>## 列表测试+ 列表测试，行1+ 列表测试，行2+ 列表测试，行3+ 列表测试，行4## 表格测试A | B | C--|--|--A1 | B1 | C1A2 | B2 | C2A3 | B3 | C3</code></pre><p>转换后的html</p><pre><code>&lt;h1 id=&quot;marked-demo&quot;&gt;Marked Demo&lt;/h1&gt;&lt;p&gt;这是一个Marked库使用的例子。 &lt;a href=&quot;http://blog.fens.me/nodejs-markdown-marked/&quot;&gt;http://blog.fens.me/nodejs-man-marked/&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;A full-featured markdown parser and compiler, written in JavaScript. Builtfor speed.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;[&lt;img src=&quot;https://badge.fury.io/js/marked.png&quot; alt=&quot;NPM version&quot;&gt;][badge]&lt;/p&lt;&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;npm install marked --save&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;-&quot;&gt;列表测试&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;列表测试，行1&lt;/li&gt;&lt;li&gt;列表测试，行2&lt;/li&gt;&lt;li&gt;列表测试，行3&lt;/li&gt;&lt;li&gt;列表测试，行4&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;-&quot;&gt;表格测试&lt;/h2&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;A&lt;/th&gt;&lt;th&gt;B&lt;/th&gt;&lt;th&gt;C&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;A1&lt;/td&gt;&lt;td&gt;B1&lt;/td&gt;&lt;td&gt;C1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;A2&lt;/td&gt;&lt;td&gt;B2&lt;/td&gt;&lt;td&gt;C2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;A3&lt;/td&gt;&lt;td&gt;B3&lt;/td&gt;&lt;td&gt;C3&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</code></pre><h2 id="mathjax">mathjax</h2><p><a href="https://mathjax-chinese-doc.readthedocs.io/en/latest/mathjax.html" target="_blank" rel="noopener">MathJax</a>是一个开源JavaScript库。它支持LaTeX、MathML、AsciiMath符号，可以运行于所有流行浏览器上。 它的设计目标是利用最新的web技术，构建一个支持math的web平台。支持主要的浏览器和操作系统,包括那些移动设备。使用MathJax显示数学公式是基于文本的，而非图片。它可以被搜索引擎使用，这意味着方程式和页面上的文字一样是可以被搜索的。 MathJax允许页面作者使用TeX、LaTeX符号和 MathML 或者 AsciiMath 去书写公式。 MathJax甚至可以将Tex格式转化为MathML格式，使其可以被原生支持MathML格式的浏览器更多的渲染。转化为MathML格式后你可以复制粘贴它们到其他程序中。</p><p>MathJax允许你在你的网页中包含公式，无论是使用LaTeX、MathML或者AsciiMath符号，这些公式都会被javascript处理为HTML、SVG或者MathML符号。具体栗子：</p><pre><code>&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;MathJax TeX Test Page&lt;/title&gt;&lt;script type=&quot;text/x-mathjax-config&quot;&gt;  MathJax.Hub.Config({tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}});&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;  src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;When $a \ne 0$, there are two solutions to \(ax^2 + bx + c = 0\) and they are$$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$&lt;/body&gt;&lt;/html&gt;</code></pre><p>在这个栗子中，分为几个部分：</p><ol type="1"><li><p>加载MathJax:使用MathJax的内容发布网络(CDN),这样就会从分发服务器中加载最新版本的MathJax，并配置它识别用Tex和MathML符号书写的公式。如果浏览器原生支持MathML格式，MathJax就会生成用MathML输出，不然的话就用HTML和CSS去显示公式。这是最常见的配置，它可以满足大部分人的需求.</p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script></li><li>设置公式分隔符：使用 TeX 和 LaTeX 格式的公式使用 公式分隔符 环绕公式，即告知MathJax页面哪个部分代码公式和它的基本格式。 这里有两种形式的公式：<ol type="1"><li>包含在段落之中的</li><li>独立于其他文字的</li></ol><p>默认的公式分隔符是 <span class="math display">\[...\]</span> 和 […] ，还有 (…) 常用于段落中的公式。请特别注意， (…) 分隔符 不是 默认使用的。美元符号$常常在其他情况下使用，这会导致本文被错误的当做公式解析了。</p><p>例如，使用美元分隔符的情况下， ”… the cost is $2.50 for the first one, and $2.00 for each additional one …” 会被处理为 “2.50 for the first one, and” 。因为介于美元符号之间的文字内容被当做公式处理了。基于这样的理由，如果你想使用美元分隔符，请在配置文件中显示声明</p><pre><code> &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({   tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]} }); &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;path-to-mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;</code></pre></li><li><p>写公式：</p><pre><code> When $a \ne 0$, there are two solutions to \(ax^2 + bx + c = 0\) and they are $$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$</code></pre></li></ol><p>以上基本摘自MathJax的文档.</p><h2 id="markedmathjaxmarkdown">Marked+MathJax+Markdown</h2><p>好了上面我们介绍了Marked和MathJax，是不是markdown到html并能顺利展示已经解决了，貌似也不用费什么心思了。但是使用marked.js去解析我们写的markdown，比如一些符号，<code>_</code>代表斜体会被处理为<code>&lt;em&gt;</code>标签，比如在<code>x_i</code>开始被渲染的时候，处理为x<em>i</em>，这个时候mathjax就无法渲染成下标了。很多符号都有这个问题，比如粗体*,也是无法在mathjax渲染出来的，好在有替代的乘法等,包括\同理。因此问题就是Marked在解析转换markdown时没有考虑数学公式的问题.这里有个解决方法<a href="http://shomy.top/2016/10/22/hexo-markdown-mathjax/" target="_blank" rel="noopener">Hexo下mathjax的转义问题</a></p><blockquote><p>2018-02-05 为了彻底解决问题，免去各种配置问题，我直接转为Pandoc引擎进行markdown文件的渲染。</p></blockquote><h1 id="本地可视化编辑">本地可视化编辑</h1><p>本地化编辑我是用的MarkdownPad,在这个编辑器中公式不能直接浏览，需要在网页中查看。相关配置：在markdown文件中内容部分直接加入：</p><pre><code>---title: math formate in hexodate: 2018-02-03 22:28:15tags:- hexocategories:- hexo---hexo中使用数学公式的一个解决方法和相应的公式符号。&lt;!-- more --&gt;&lt;script type=&quot;text/x-mathjax-config&quot;&gt;MathJax.Hub.Config({tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}});&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; async  src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</code></pre><p>然后在“工具-&gt;在浏览器中浏览”就可以了，当然为了省去每次在在文件中粘贴的麻烦，可以在“工具-&gt;选项-&gt;高级-&gt;自定义Html Head”中加入即可。</p><pre><code>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;MathJax.Hub.Config({tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}});&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; async  src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</code></pre><p>当然有很多其他直接浏览的工具，如cmd Markdown, stackEdit等。按需自取吧。</p><h1 id="简单公式">简单公式</h1><p>可以直接参考<a href="http://easy-copy-mathjax.xxxx7.com/" target="_blank" rel="noopener">Easy Copy MathJax</a> 中数学公式的MathJax识别的符号。下面是自己经常用的一些记录。 ## 行中公式 对于一个线性方程 \( y=a*x+b\)</p><p><span class="math display">\[f&#39;(x\_0)=\lim_{\Delta x\to 0} \frac{f(x\_0+\Delta x) - f(x\_0)}{\Delta x}\]</span></p><h1 id="资料">资料</h1><ol type="1"><li><a href="http://daniellaah.github.io/2016/Mathmatical-Formula-within-Markdown.html" target="_blank" rel="noopener">如何在Hexo博客中插入数学公式</a></li><li>Markdown+math 编辑器<a href="https://github.com/benweet/stackedit/" target="_blank" rel="noopener">StackEdit</a></li><li><a href="http://pages.tzengyuxio.me/pandoc/" target="_blank" rel="noopener">Pandoc markdown语法</a></li><li><a href="http://blog.csdn.net/ethmery/article/details/50670297" target="_blank" rel="noopener">mathjax常用数学符号</a></li></ol>]]></content>
    
    <summary type="html">
    
      hexo中使用数学公式的一个简单介绍（非教程），全当记录自己的想法，等自己探索差不多后会沉淀成教程。
    
    </summary>
    
      <category term="hexo" scheme="https://leaveslr.github.io/categories/hexo/"/>
    
    
      <category term="hexo" scheme="https://leaveslr.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>A Neural Autoregressive Approach to Collaborative Filtering</title>
    <link href="https://leaveslr.github.io/2018/02/03/A-Neural-Autoregressive-Approach-to-Collaborative-Filtering/"/>
    <id>https://leaveslr.github.io/2018/02/03/A-Neural-Autoregressive-Approach-to-Collaborative-Filtering/</id>
    <published>2018-02-03T07:57:17.000Z</published>
    <updated>2018-02-05T05:10:04.453Z</updated>
    
    <content type="html"><![CDATA[本篇文章是在16年的一个阅读论文的笔记，讨论了RBM和NADE在协同过滤上的应用，重点是hulu公司同事的ICML的文章<a href="https://arxiv.org/pdf/1605.09477.pdf" target="_blank" rel="noopener">A Neural Autoregressive Approach to Collaborative Filtering</a>,介绍了利用NADE进行电影推荐的方法。 <a id="more"></a><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><h1 id="rbm-and-nade-to-collaborative-filtering">RBM and NADE TO Collaborative Filtering</h1><p>最近在看深度学习在推荐算法上应用，本篇是hulu公司同事的ICML的文章<a href="https://arxiv.org/pdf/1605.09477.pdf" target="_blank" rel="noopener">A Neural Autoregressive Approach to Collaborative Filtering</a>,介绍了利用NADE进行电影推荐的方法，在NETFX的数据集上取得了不错的结果，本文主要是学习和记录笔记，学习NADE-CF，并记录所涉及的一些算法，供后续查看方便。</p><h2 id="rbm">RBM</h2><p>RBM主要参考<a href="www.paper.edu.cn/download/downPaper/201301-528">受限波尔兹曼机简介-张春霞</a>,同时也参考核复制了博客的很多内容<a href="http://blog.csdn.net/mytestmy/article/details/9150213" target="_blank" rel="noopener">深度学习读书笔记之RBM（限制波尔兹曼机)</a>。在这里主要简介RBM涉及的几个计算公式，方便后边实现的理解。 <img src="http://img.blog.csdn.net/20130628222803078?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbXl0ZXN0bXk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="RBM流程图"> #### 能量函数 能量函数。随机神经网络是根植于统计力学的。受统计力学中能量泛函的启发，引入了能量函数。能量函数是描述整个系统状态的一种测度。系统越有序或者概率分布越集中，系统的能量越小。反之，系统越无序或者概率分布越趋于均匀分布，则系统的能量越大。能量函数的最小值，对应于系统的最稳定状态。</p><p><span class="math display">\[ E(v,h|\theta)=-\sum_{i=0}^{n}{a_i v_i} -\sum_{j=0}^{m}{b_jh_j} -\sum_{i=0}^{n} {\sum_{j=0}^{m} {v_i W_{ij} h_j} } \]</span></p><p>其中，\(a_i\) 和 \(b_j\) 为偏置，\(v_i\) 为可见层，\(h_j\) 为隐藏层。</p><h4 id="似然函数">似然函数</h4><p>有了能量函数，定义可视节点和隐藏层的联合概率分布。 <span class="math display">\[ p(v,h|\theta) = \frac{e^{-{E(v,h|\theta)}}} {Z(\theta)} \]</span></p><p><span class="math display">\[ Z(\theta)=\sum_{v,h} {e^{-{E(v,h|\theta)}}} \]</span> 由联合概率可以得到观测数据\(v\)的概率分布$ p(v|)$ ,也成为似然函数 <span class="math display">\[p(v|\theta) = -\frac{1}{Z(\theta)}\sum_h{e^{-{E(v,h|\theta)}}}\]</span> 同理，可以获得每个节点的激发函数,RBN层内节点不连接，同一层各节点独立分布。 <span class="math display">\[p(v_i=1|h,\theta) = \sigma(a_i+\sum_j{h_j W_{ij}})\]</span> <span class="math display">\[p(h_i=1|v,\theta) = \sigma(b_i+\sum_i{v_i W_{ij}})\]</span></p><h4 id="对比散度rbm参数训练">对比散度RBM参数训练</h4><p>学习RBM的任务是求出参数\(theta\)的值, 以拟合给定的训练数据。 参数\(theta\)可以通过最大 化RBM在训练集昨假设包含T个样本昩上的对数似然函数学习得到, 即 <span class="math display">\[\Theta^* = {arg\max}_{\theta}({\xi(\theta)}) = {arg\max}_{\theta}{\sum_{t=1}^{T} {logp(v^{t}|\theta)}}\]</span> Hiton提出了RBM的一个快速学习算法, 即对比散度(Contrastive Divergence)。与吉布斯采样不同, CD指出当使用训练数据初始化\(v_0\) 时, 我们仅需要使用k步吉布斯采样便可以得到足够好的近似。在CD算法一开始， 可见单元的状态被设置成一个训练样本，并利用式\(p(h|v,) \)计算所有隐层单元的二值状态。在所有隐层单元的状态确定之后,来确定第i个可见单元\(v_i\)取值为1的概率,进而产生可见层的一个重构。</p><ul><li>输入:一个训练样本\(m_0\),隐层单元个数\(m\),学习率\( \epsilon \),最大训练周期\( T\).</li><li>输出:连接权重矩阵W、可见层的偏置向量a、隐层的偏置向量b.</li><li>训练阶段:<ul><li>初始化可见层单元的初始状态\(v1=x_0;W a\)和b为随机的较小数值。</li><li>For t=1,2…T<ul><li>For j=1,2..m(对所有隐层单元)<ul><li>计算隐层节点分布\( (p(h_{1j}=1|v_1) \), <span class="math display">\[ p(h_{1j}=1|v_1) = \sigma(b_j+\sum_i{v_{1i} W_{ij}}) \]</span></li><li>计算隐层节点\(h_{1j} \),从条件\(p(h_{1j}=1|v_1) \) 中抽样\(h_{1j}= {0,1} \),具体\(h_{1j}=p(h_{1j}=1|v_1)&gt;Rand(numHidden+1)? 1:0 \)</li></ul></li><li>EndFor</li><li>For i=1,2,….,n(对所有可见层单元)<ul><li>计算\( (p(v_{2i}=1|h_1) \), <span class="math display">\[ p(v_{2i}=1|h_1) = \sigma(a_i+\sum_j{h_j W_{ij}}) \]</span></li><li>计算节点\(v_{1i} \),从条件\(p(v_{1j}=1|h_1) \)中抽样\(v_{1i}= {0,1} \),具体\(v_{1i}=p(v_{1i}=1|h_1) \)(参考下文中代码实现)</li></ul></li><li>EndFor</li><li>For 1,2,…,m（对所有隐层单元）<ul><li>计算隐层节点分布\( p(h_{2j}=1|v_2) \) ,<span class="math display">\[ p(h_{2j}=1|v_2) = \sigma(b_j+\sum_i{v_{2i} W_{ij}}) \]</span></li></ul></li><li>EndFor</li><li>参数更新(根据上文的导数可以求得)<ul><li><span class="math display">\[ W=W+(p(h_{1}=1|v_1)v^T_1-p(h_{2}=1|v_2))v^T_2 \]</span></li><li><span class="math display">\[ a=a+(v_1-v_2) \]</span></li><li><span class="math display">\[ b=b+(p(h_{1}=1|v_1)-p(h_{2}=1|v_2)) \]</span></li></ul></li></ul></li></ul></li></ul><p>python code 参考训练过程 $$ def train(self, data, max_epochs = 1000): “”&quot; Train the machine. Parameters ———- data: A matrix where each row is a training example consisting of the states of visible units.<br>“”&quot;</p><pre><code>num_examples = data.shape[0]# Insert bias units of 1 into the first column.data = np.insert(data, 0, 1, axis = 1)for epoch in range(max_epochs):        # Clamp to the data and sample from the hidden units.   # (This is the &quot;positive CD phase&quot;, aka the reality phase.)  pos_hidden_activations = np.dot(data, self.weights)        pos_hidden_probs = self._logistic(pos_hidden_activations)  pos_hidden_states = pos_hidden_probs &gt; np.random.rand(num_examples, self.num_hidden + 1)  # Note that we&#39;re using the activation *probabilities* of the hidden states, not the hidden states         # themselves, when computing associations. We could also use the states; see section 3 of Hinton&#39;s   # &quot;A Practical Guide to Training Restricted Boltzmann Machines&quot; for more.  pos_associations = np.dot(data.T, pos_hidden_probs)  # Reconstruct the visible units and sample again from the hidden units.  # (This is the &quot;negative CD phase&quot;, aka the daydreaming phase.)  neg_visible_activations = np.dot(pos_hidden_states, self.weights.T)  neg_visible_probs = self._logistic(neg_visible_activations)  neg_visible_probs[:,0] = 1 # Fix the bias unit.  neg_hidden_activations = np.dot(neg_visible_probs, self.weights)  neg_hidden_probs = self._logistic(neg_hidden_activations)  # Note, again, that we&#39;re using the activation *probabilities* when computing associations, not the states   # themselves.  neg_associations = np.dot(neg_visible_probs.T, neg_hidden_probs)  # Update weights.  self.weights += self.learning_rate * ((pos_associations - neg_associations) / num_examples)  error = np.sum((data - neg_visible_probs) ** 2)  print(&quot;Epoch %s: error is %s&quot; % (epoch, error))</code></pre><p>$$</p><p>如果详细的了解过程，可以看一下github上代码<a href="https://github.com/echen/restricted-boltzmann-machines" target="_blank" rel="noopener">Restricted Boltzmann Machines in Python</a></p><h2 id="rbm-cf">RBM-CF</h2><p>有了以上对RBM的介绍和认识，接下来的RBM-CF的原理就很好理解了。<a href="http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf" target="_blank" rel="noopener">Restricted Boltzmann Machines in Python</a>是Hinton大牛在2007ICML上提出的,在netfext上也取得了不错的效果。下面就详细的介绍一下算法。 <img src="http://img.blog.csdn.net/20160924172416013" alt="image"> 如图所示，RBM-CF是一个标准的RBM。其中V是用户对电影的评分（如图是5个级别）.可见层为用户对电影的评分向量，隐层为隐向量。 ### 能量函数和似然函数 <span class="math display">\[E(v,h|\theta)=-\sum_{i=1}^{n}{\sum_{k=1}^{K}{a_iv^k_i}}-\sum_{j=1}^{m}{b_jh_j}-\sum_{i=1}^{n}\sum_{j=1}^{m}{\sum_{k=1}^{K}{v^k_i}W_{ij}h_j}+\sum_{i=1}^M{logZ_i}\]</span> 其中，<span class="math display">\[ Z_i=\sum^k_{l=1}{exp(b_i^l+\sum_j{h_jWw_{ij}})} \]</span> 对应的似然函数： <span class="math display">\[p(v|\theta) = -\frac{1}{Z(\theta)}\sum_h{e^{-{E(v,h|\theta)}}}\]</span> 有了以上的定义，可以获得隐层和可见层的分布： <span class="math display">\[p(v_i^k=1|h,\theta) = \frac{exp(a_i^k+\sum_j{h_j W_{ij}^k})}{\sum_{l=1}^Kexp(a_i^l+\sum_j{h_j W_{ij}^l})}\]</span> <span class="math display">\[p(h_j=1|v,\theta) = \sigma(b_j+\sum_{i=1}^m{\sum_{k=1}^K{v_i W_{ij}^k})}\]</span></p><h3 id="conditional-rbms">Conditional RBM’s</h3><p>其实在NetFlix的数据中，用户对电影的评分是比较稀疏。有大量的用户观看了电影没有评分，因此作者为了将此类信息加入到模型中，增加模型对用户评分的准确性。如图，将用户的观看列表信息加入到隐层中。 <img src="http://img.blog.csdn.net/20160924172457545" alt="image"> 原先每个隐层的分布变为： <span class="math display">\[p(h_j=1|v,\theta) = \sigma(b_j+\sum_{i=1}^m{\sum_{k=1}^K{v_i W_{ij}^k})+\sum_{i=1}^M{r_iD_{ij}}}\]</span> 由于参数D与可见层无关，可以作为和b偏置一样的功能，参数更新也一样。</p><h2 id="nade">NADE</h2><p>NADE是Hugo Larochelle在2011年提出，论文<a href="http://www.jmlr.org/proceedings/papers/v15/larochelle11a/larochelle11a.pdf" target="_blank" rel="noopener">The Neural Autoregressive Distribution Estimator</a>。具体引入NADE的原因还不是特别懂，看论文 <code>We describe a new approach for modeling the distribution of high-dimensional vectors of discrete variables. This model is inspired by the restricted Boltzmann machine (RBM), which has been shown to be a powerful model of such distributions. However, an RBM typically does not provide a tractable distribution estimator, since evaluating the probability it assigns to some given observation requires the computation of the so-called partition function, which itself is intractable for RBMs of even moderate size.</code> ### 可见层分布 将RBM贝叶斯网络化，v为可见层节点，\( v_{parent(i)} \)可以理解为\(v_i\)的网络中的隐层节点。那么可见层的分布为： <span class="math display">\[p(v)=\prod^D_i{p(v_i|v_{parents(i)})}\]</span> 现在有两种表征\(p(v_i|v_{parents(i)}) \)的方式，分别为FVSBM和NADE. <img src="http://img.blog.csdn.net/20160925113216371" alt="image"> #### FVSBM <span class="math display">\[p(v_i|v_{parents(i)})=sigm(b_i+\sum_{j&lt;i}{W_{ij}v_j})\]</span></p><h4 id="nade-1">NADE</h4><p><span class="math display">\[p(v_i=1|v_{&lt;i})=sigm(b_i+{(W^T)_{i}.h_i})\]</span> <span class="math display">\[h_i=sigm(c+{W,_{&lt;i}v_{&lt;i}})\]</span> 以上是NADE的可见层的分布公式，下面是求解流程：</p><ul><li>#计算p(v)</li><li>a=c</li><li>p(v)=0</li><li>For i=1,2,…,D:<ul><li>\(h_i=sigm(a) \)</li><li>\(p(v_i=1|v_{&lt;i})=simg(b_i+V_i.h_i) \)</li><li>\(p(v)=p(v)(p(v_i=1|v_{&lt;i})^{v_i} + (1-p(v_i=1|v_{&lt;i})^{1-v_i})) \)</li><li>\(a=a+W.,_iv_i \)</li></ul></li><li>EndFor</li><li></li><li>计算梯度\( -log(p(v)) \)</li><li>\( \Delta{a}=0 \)</li><li>\( \Delta{c} = 0\)</li><li>For i,2,…,D:<ul><li>\( {\Delta{b_i}}=p(v_i=1|v_{&lt;i}) - v_i \)</li><li>\( {\Delta{V_i}}=(p(v_i=1|v_{&lt;i}) - v_i)h^T_i \)</li><li>\( {\Delta{h_i}}=(p(v_i=1|v_{&lt;i}) - v_i)V^T_i \)</li><li>\( {\Delta{c}}=\Delta{c}+(\Delta{h_i})h_i(1-h_i) \)</li><li>\( \Delta{W,_i} = (\Delta{a})v_i \)</li><li>\( {\Delta{a}}=+(\Delta{h_i})h_i(1-h_i) \)</li></ul></li><li>EndFor</li><li>参数更新 ## NADE-CF 在以上铺垫后，就是讲应用加入到模型就行了。先定义一些参数\( r^u = r^u_{m_{o1}} \), \( r^u_{m_{o2}} \) ,.., \( r^u_{m_{oD}} \) 为用户的评分序列，\( r^u_{m_{oi}} \)为用户的评分，在1-k之间。 <span class="math display">\[p(r)=\prod^D_{i=1}{p(r_{m_{oi}} | r_{m_{o&lt;i}})}\]</span> <span class="math display">\[h(r_{m_{o&lt;i}})=g(c+\sum_{j&lt;i}W^{r_{m_{oj}}}_{m_{oj}})\]</span> 另外，若写成每个用户对每个电影在评分K上的分布： <span class="math display">\[p(r_{m_{oi}}=k|r_{m_{o&lt;i}}) = \frac{exp(s^k_{m_{oi}}(r_{m_{o&lt;i}}))}{\sum^K_q{exp(s^q_{m_{oi}}(r_{m_{o&lt;i}}))}}\]</span> <span class="math display">\[s^k_{m_{oi}}(r_{m_{o&lt;i}}) = b^k_{m_{oi}} + V^k_{m_{oi}}h(r_{m_{o&lt;i}})\]</span> ### 目标函数 <span class="math display">\[-logp(r) = -\sum^D_i{logp(r_{m_{oi}}|r_{m_{o&lt;i}}})\]</span> ### 参数共享 <span class="math display">\[h(r_{m_{o&lt;i}})=g(c+\sum_{j&lt;i}{\sum^{r_{m_{oj}}}_kW^{k}_{m_{oj}}})\]</span> <span class="math display">\[s^k_{m_{oi}}(r_{m_{o&lt;i}}) = \sum_{j&lt;k}{b^k_{m_{oi}} + V^k_{m_{oi}}h(r_{m_{o&lt;i}})}\]</span></li></ul>]]></content>
    
    <summary type="html">
    
      本篇文章是在16年的一个阅读论文的笔记，讨论了RBM和NADE在协同过滤上的应用，重点是hulu公司同事的ICML的文章&lt;a href=&quot;https://arxiv.org/pdf/1605.09477.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;A Neural Autoregressive Approach to Collaborative Filtering&lt;/a&gt;,介绍了利用NADE进行电影推荐的方法。
    
    </summary>
    
    
      <category term="机器学习" scheme="https://leaveslr.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文" scheme="https://leaveslr.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>hexo+next 博客系统搭建</title>
    <link href="https://leaveslr.github.io/2018/02/02/hexo-next-%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/"/>
    <id>https://leaveslr.github.io/2018/02/02/hexo-next-博客系统搭建/</id>
    <published>2018-02-02T08:36:35.000Z</published>
    <updated>2018-02-05T06:33:03.260Z</updated>
    
    <content type="html"><![CDATA[<p>自己搭建博客的一些参考资料，记录防止以后用到。并非教程。未完成，待补充：discus评论系统，加入百度、google的统计。 <a id="more"></a> # 博客的搭建 # 博客的个性化设置 ## 文章阅读次数 本博客的阅读次数统计使用的是leanCloud账号，注册相对简单，具体步骤：</p><ol type="1"><li>创建LeanCloud账号<a href="https://leancloud.cn/" target="_blank" rel="noopener">LeanCloud</a></li><li>创建应用：注册并登录LeanCloud后，进入控制台，单击“创建应用”按钮进行应用的创建，输入新应用名称，选择开发版，单击“创建”按钮完成创建。 <img src="https://upload-images.jianshu.io/upload_images/291600-a114303ec633d628.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700"></li><li><p>创建Class:进入到刚刚创建的应用中，选择左侧导航栏的“存储”，然后点击“创建Class”，为了与NexT形成配置关系，将Class名称填为Counter，并选择无限制选项，然后单击“创建Class”按钮完成Class的创建，如下图所示：<img src="https://upload-images.jianshu.io/upload_images/291600-47b6f370eeb9384f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700"></p><p>点击刚刚创建的Counter，其实质是一张结构表，用来记录文章的浏览量，如下图所示，这里的表可以直接对文章阅读次数进行修改，所以如果想要追求阅读次数的读者可以在表上直接进行修改。</p></li><li><p>配置key:在左侧导航栏的设置界面，单击“应用Key”可以看到应用的App ID和App Key。复制ID和Key，然后将其配置到主题配置文件中，在文件中找到leancloud_visitors属性，将enable设置为true，然后将之前复制的ID和Key粘贴到相应的属性中。</p></li></ol><h2 id="分享">分享</h2><p>一开始用的 JiaThis, 后发现发不上去就不显示。后使用的needmoreshare2。</p><pre><code># NeedMoreShare2# This plugin is a pure javascript sharing lib which is useful in China.# See: https://github.com/revir/need-more-share2# Also see: https://github.com/DzmVasileusky/needShareButton# iconStyle: default | box# boxForm: horizontal | vertical# position: top / middle / bottom + Left / Center / Right# networks: Weibo,Wechat,Douban,QQZone,Twitter,Linkedin,Mailto,Reddit,#           Delicious,StumbleUpon,Pinterest,Facebook,GooglePlus,Slashdot,#           Technorati,Posterous,Tumblr,GoogleBookmarks,Newsvine,#           Evernote,Friendfeed,Vkontakte,Odnoklassniki,Mailruneedmoreshare2:  enable: true  postbottom:    enable: true    options:      iconStyle: default      boxForm: horizontal      position: bottomCenter      networks: Weibo,Wechat,Douban,QQZone,Twitter,Facebook float:    enable: false    options:      iconStyle: box      boxForm: horizontal</code></pre><h2 id="评论系统">评论系统</h2><p>一开始折腾了使用 <a href="http://www.uyan.cc/" target="_blank" rel="noopener">友言</a>,发现一直出不来效果，就果断放弃了（后期看看加入好的评论系统）。然后转向了简单的<a href="https://valine.js.org/" target="_blank" rel="noopener">Valine</a>.</p><p>Valine一款快速、简洁且高效的无后端评论系统,基于Leancloud开发。具体流程：</p><ol type="1"><li>创建LeanCloud账号<a href="https://leancloud.cn/" target="_blank" rel="noopener">LeanCloud</a> 并获取 App ID和App Key。</li><li><p>配置：</p><pre><code> # Valine. # You can get your appid and appkey from https://leancloud.cn # more info please open https://valine.js.org valine: enable: true appid: ***** appkey: **** notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: Just go go # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size </code></pre></li></ol><h2 id="布局大小调整">布局大小调整</h2><p>一开始用的next默认的布局，但是看到<a href="http://jmyblog.top" target="_blank" rel="noopener">jmyblog</a>后，发现自己的布局可以调整，就尝试调整了一下，在官方文章中设置内容区域布局：NexT 对于内容的宽度的设定如下：700px，当屏幕宽度 &lt; 1600px；900px，当屏幕宽度 &gt;= 1600px；移动设备下，宽度自适应。</p><p>如果你需要修改内容的宽度，同样需要编辑样式文件。 编辑主题的 source/css/_variables/custom.styl 文件，新增变量：</p><pre><code>// 修改成你期望的宽度$content-desktop = 700px// 当视窗超过 1600px 后的宽度$content-desktop-large = 900px</code></pre><p>但是对于Pisces Scheme，需要单独配置source/css/_variables/custom.styl：</p><pre><code>.header{ width: 90%; }.container .main-inner { width: 90%; }.content-wrap { width: calc(100% - 260px); }</code></pre><h2 id="侧边栏调整">侧边栏调整</h2><h2 id="文末版权信息">文末版权信息</h2><h2 id="站点访问人数">站点访问人数</h2><p>具体实现方法，在_partials.swig文件中，在copyright前加以下代码：</p><pre><code>&lt;script async src=&quot;https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;</code></pre><p>在再合适的位置添加显示统计的代码：</p><pre><code>&lt;div class=&quot;powered-by&quot;&gt;&lt;i class=&quot;fa fa-user-md&quot;&gt;&lt;/i&gt;&lt;span id=&quot;busuanzi_container_site_uv&quot;&gt;  访客:&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;  浏览:&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;  &lt;/span&gt;&lt;/div&gt;</code></pre><h2 id="文章字数统计">文章字数统计</h2><ol type="1"><li>切换到根目录下，然后运行如下代码 <code>$ npm install hexo-wordcount --save</code></li><li><p>然后在主题的配置文件中，配置如下：</p><pre><code> # Post wordcount display settings # Dependencies: https://github.com/willin/hexo-wordcount post_wordcount: item_text: true wordcount: true min2read: true</code></pre></li></ol><h2 id="修改文章底部的那个带号的标签">修改文章底部的那个带#号的标签</h2><p>修改模板/themes/next/layout/_macro/post.swig，搜索 <code>rel=&quot;tag&quot;&gt;#</code>，将 <code>#</code> 换成<code>&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;</code></p><h2 id="网站底部次数统计">网站底部次数统计</h2><p>需要使用hexo-wordcount 具体步骤：</p><ol type="1"><li>切换到根目录下，然后运行如下代码 <code>$ npm install hexo-wordcount --save</code></li><li>然后在/themes/next/layout/_partials/footer.swig文件尾部加上：</li></ol><h2 id="加入百度">加入百度</h2><h1 id="hexonext-资料">hexo+next 资料</h1><ol type="1"><li>next官方： http://theme-next.iissnan.com/</li><li>hexo的next主题个性化教程：打造炫酷网站 http://blog.csdn.net/qq_33699981/article/details/72716951</li><li>一个好的布局：http://jmyblog.top/</li><li>布局优化：http://blog.csdn.net/heqiangflytosky/article/details/54863185</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;自己搭建博客的一些参考资料，记录防止以后用到。并非教程。未完成，待补充：discus评论系统，加入百度、google的统计。
    
    </summary>
    
      <category term="hexo" scheme="https://leaveslr.github.io/categories/hexo/"/>
    
    
      <category term="hexo" scheme="https://leaveslr.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>hello word</title>
    <link href="https://leaveslr.github.io/2018/02/02/hello-word/"/>
    <id>https://leaveslr.github.io/2018/02/02/hello-word/</id>
    <published>2018-02-02T07:01:51.000Z</published>
    <updated>2018-02-03T14:01:45.753Z</updated>
    
    <content type="html"><![CDATA[<p>This is a summary of the post. <a id="more"></a></p><pre><code>$$\frac{7x+5}{1+y^2}$$</code></pre><p>##Say you have a lenghty post and don’t like the fact that the entire article is displayed in the listing pages… You can mark a spot in your markdown with <!-- more --> to hide it from the listing pages. It will be replaced with a “Read more” link that will open the rest of the article content.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is a summary of the post.
    
    </summary>
    
      <category term="个人" scheme="https://leaveslr.github.io/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="个人" scheme="https://leaveslr.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
</feed>

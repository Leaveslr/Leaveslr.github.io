<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>菜叶</title>
  
  <subtitle>快乐、奋斗、加油</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://leaveslr.github.io/"/>
  <updated>2018-02-03T10:13:08.838Z</updated>
  <id>https://leaveslr.github.io/</id>
  
  <author>
    <name>刘荣</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>A Neural Autoregressive Approach to Collaborative Filtering</title>
    <link href="https://leaveslr.github.io/2018/02/03/A-Neural-Autoregressive-Approach-to-Collaborative-Filtering/"/>
    <id>https://leaveslr.github.io/2018/02/03/A-Neural-Autoregressive-Approach-to-Collaborative-Filtering/</id>
    <published>2018-02-03T07:57:17.000Z</published>
    <updated>2018-02-03T10:13:08.838Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RBM-and-NADE-TO-Collaborative-Filtering"><a href="#RBM-and-NADE-TO-Collaborative-Filtering" class="headerlink" title="RBM and NADE TO Collaborative Filtering"></a>RBM and NADE TO Collaborative Filtering</h1><p>最近在看深度学习在推荐算法上应用，本篇是hulu公司同事的ICML的文章<a href="https://arxiv.org/pdf/1605.09477.pdf" target="_blank" rel="noopener">A Neural Autoregressive Approach to Collaborative Filtering</a>,介绍了利用NADE进行电影推荐的方法，在NETFX的数据集上取得了不错的结果，本文主要是学习和记录笔记，学习NADE-CF，并记录所涉及的一些算法，供后续查看方便。</p><h2 id="RBM"><a href="#RBM" class="headerlink" title="RBM"></a>RBM</h2><p>RBM主要参考<a href="www.paper.edu.cn/download/downPaper/201301-528">受限波尔兹曼机简介-张春霞</a>,同时也参考核复制了博客的很多内容<a href="http://blog.csdn.net/mytestmy/article/details/9150213" target="_blank" rel="noopener"> 深度学习读书笔记之RBM（限制波尔兹曼机)</a>。在这里主要简介RBM涉及的几个计算公式，方便后边实现的理解。<br><img src="http://img.blog.csdn.net/20130628222803078?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbXl0ZXN0bXk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="RBM流程图"></p><h4 id="能量函数"><a href="#能量函数" class="headerlink" title="能量函数"></a>能量函数</h4><p>能量函数。随机神经网络是根植于统计力学的。受统计力学中能量泛函的启发，引入了能量函数。能量函数是描述整个系统状态的一种测度。系统越有序或者概率分布越集中，系统的能量越小。反之，系统越无序或者概率分布越趋于均匀分布，则系统的能量越大。能量函数的最小值，对应于系统的最稳定状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E(v,h|\theta)=-\sum_&#123;i=0&#125;^&#123;n&#125;&#123;a_iv_i&#125;-\sum_&#123;j=0&#125;^&#123;m&#125;&#123;b_jh_j&#125;-\sum_&#123;i=0&#125;^&#123;n&#125;\sum_&#123;j=0&#125;^&#123;m&#125;&#123;&#123;v_i&#125;W_&#123;ij&#125;h_j&#125;</span><br></pre></td></tr></table></figure><p>其中，\(a_i\) 和 \(b_j\) 为偏置，\(v_i\) 为可见层，\(h_j\) 为隐藏层。</p><h4 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h4><p>有了能量函数，定义可视节点和隐藏层的联合概率分布。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v,h|\theta) = \frac&#123;e^&#123;-&#123;E(v,h|\theta)&#125;&#125;&#125; &#123;Z(\theta)&#125;,</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z(\theta)=\sum_&#123;v,h&#125; &#123;e^&#123;-&#123;E(v,h|\theta)&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><p>由联合概率可以得到观测数据\(v\)的概率分布\(p(v|\theta)$`，也成为似然函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v|\theta) = -\frac&#123;1&#125;&#123;Z(\theta)&#125;\sum_h&#123;e^&#123;-&#123;E(v,h|\theta)&#125;&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>同理，可以获得每个节点的激发函数,RBN层内节点不连接，同一层各节点独立分布。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v_i=1|h,\theta) = \sigma(a_i+\sum_j&#123;h_j W_&#123;ij&#125;&#125;)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(h_i=1|v,\theta) = \sigma(b_i+\sum_i&#123;v_i W_&#123;ij&#125;&#125;)</span><br></pre></td></tr></table></figure><h4 id="对比散度RBM参数训练"><a href="#对比散度RBM参数训练" class="headerlink" title="对比散度RBM参数训练"></a>对比散度RBM参数训练</h4><p>学习RBM的任务是求出参数<code>$\theta\\)的值, 以拟合给定的训练数据。 参数</code>$\theta\)可以通过最大<br>化RBM在训练集昨假设包含T个样本昩上的对数似然函数学习得到, 即<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Theta^* = &#123;arg\max&#125;_&#123;\theta&#125;(&#123;\xi(\theta)&#125;) = &#123;arg\max&#125;_&#123;\theta&#125;&#123;\sum_&#123;t=1&#125;^&#123;T&#125; &#123;logp(v^&#123;t&#125;|\theta)&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>Hiton提出了RBM的一个快速学习算法, 即对比散度(Contrastive Divergence)。与吉布斯采样不同, CD指出当使用训练数据初始化\(v_0\) 时, 我们仅需要使用k步吉布斯采样便可以得到足够好的近似。在CD算法一开始， 可见单元的状态被设置成一个训练样本，并利用式\(p(h|v,\theta)$`计算所有隐层单元的二值状态。在所有隐层单元的状态确定之后,来确定第i个可见单元\(v_i\)取值为1的概率,进而产生可见层的一个重构。</p><ul><li>输入:一个训练样本\(m_0$<code>,隐层单元个数\\(m$</code>,学习率<code>$$</code>,最大训练周期\(T$`.</li><li>输出:连接权重矩阵W、可见层的偏置向量a、隐层的偏置向量b.</li><li>训练阶段:<ul><li>初始化可见层单元的初始状态\(v1=x_0;W a\)和b为随机的较小数值。</li><li>For t=1,2…T<ul><li>For j=1,2..m(对所有隐层单元)<ul><li>计算隐层节点分布\(p(h_{1j}=1|v<em>1)$<code>,</code>$p(h</em>{1j}=1|v_1) = \sigma(b_j+\sum<em>i{v</em>{1i} W_{ij}})$`</li><li>计算隐层节点\(h<em>{1j}$`,从条件\(p(h</em>{1j}=1|v<em>1)$`中抽样\(h</em>{1j}= {0,1}$`,具体\(h<em>{1j}=p(h</em>{1j}=1|v_1)&gt;Rand(numHidden+1)? 1:0\)</li></ul></li><li>EndFor</li><li>For i=1,2,….,n(对所有可见层单元)<ul><li>计算\(p(v_{2i}=1|h<em>1)$<code>,</code>$p(v</em>{2i}=1|h_1) = \sigma(a_i+\sum_j{h<em>j W</em>{ij}})$`</li><li>计算节点\(v<em>{1i}$`,从条件\(p(v</em>{1j}=1|h<em>1)$`中抽样\(v</em>{1i}= {0,1}$<code>,具体\\(v_{1i}=p(v_{1i}=1|h_1)$</code>(参考下文中代码实现)</li></ul></li><li>EndFor</li><li>For 1,2,…,m（对所有隐层单元）<ul><li>计算隐层节点分布\(p(h_{2j}=1|v<em>2)$<code>,</code>$p(h</em>{2j}=1|v_2) = \sigma(b_j+\sum<em>i{v</em>{2i} W_{ij}})$`</li></ul></li><li>EndFor</li><li>参数更新(根据上文的导数可以求得)<ul><li>\(W=W+(p(h_{1}=1|v_1)v^T<em>1-p(h</em>{2}=1|v_2))v^T_2\)</li><li>\(a=a+(v_1-v_2)$`</li><li>\(b=b+(p(h_{1}=1|v<em>1)-p(h</em>{2}=1|v_2))$`</li></ul></li></ul></li></ul></li></ul><p>python code 参考训练过程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">def train(self, data, max_epochs = 1000):</span><br><span class="line">   &quot;&quot;&quot;</span><br><span class="line">   Train the machine.</span><br><span class="line">   Parameters</span><br><span class="line">   ----------</span><br><span class="line">   data: A matrix where each row is a training example consisting of the states of visible units.    </span><br><span class="line">   &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">   num_examples = data.shape[0]</span><br><span class="line"></span><br><span class="line">   # Insert bias units of 1 into the first column.</span><br><span class="line">   data = np.insert(data, 0, 1, axis = 1)</span><br><span class="line"></span><br><span class="line">   for epoch in range(max_epochs):      </span><br><span class="line">     # Clamp to the data and sample from the hidden units. </span><br><span class="line">     # (This is the &quot;positive CD phase&quot;, aka the reality phase.)</span><br><span class="line">     pos_hidden_activations = np.dot(data, self.weights)      </span><br><span class="line">     pos_hidden_probs = self._logistic(pos_hidden_activations)</span><br><span class="line">     pos_hidden_states = pos_hidden_probs &gt; np.random.rand(num_examples, self.num_hidden + 1)</span><br><span class="line">     # Note that we&apos;re using the activation *probabilities* of the hidden states, not the hidden states       </span><br><span class="line">     # themselves, when computing associations. We could also use the states; see section 3 of Hinton&apos;s </span><br><span class="line">     # &quot;A Practical Guide to Training Restricted Boltzmann Machines&quot; for more.</span><br><span class="line">     pos_associations = np.dot(data.T, pos_hidden_probs)</span><br><span class="line"></span><br><span class="line">     # Reconstruct the visible units and sample again from the hidden units.</span><br><span class="line">     # (This is the &quot;negative CD phase&quot;, aka the daydreaming phase.)</span><br><span class="line">     neg_visible_activations = np.dot(pos_hidden_states, self.weights.T)</span><br><span class="line">     neg_visible_probs = self._logistic(neg_visible_activations)</span><br><span class="line">     neg_visible_probs[:,0] = 1 # Fix the bias unit.</span><br><span class="line">     neg_hidden_activations = np.dot(neg_visible_probs, self.weights)</span><br><span class="line">     neg_hidden_probs = self._logistic(neg_hidden_activations)</span><br><span class="line">     # Note, again, that we&apos;re using the activation *probabilities* when computing associations, not the states </span><br><span class="line">     # themselves.</span><br><span class="line">     neg_associations = np.dot(neg_visible_probs.T, neg_hidden_probs)</span><br><span class="line"></span><br><span class="line">     # Update weights.</span><br><span class="line">     self.weights += self.learning_rate * ((pos_associations - neg_associations) / num_examples)</span><br><span class="line"></span><br><span class="line">     error = np.sum((data - neg_visible_probs) ** 2)</span><br><span class="line">     print(&quot;Epoch %s: error is %s&quot; % (epoch, error))</span><br></pre></td></tr></table></figure></p><p>如果详细的了解过程，可以看一下github上代码<a href="https://github.com/echen/restricted-boltzmann-machines" target="_blank" rel="noopener">Restricted Boltzmann Machines in Python</a></p><h2 id="RBM-CF"><a href="#RBM-CF" class="headerlink" title="RBM-CF"></a>RBM-CF</h2><p>有了以上对RBM的介绍和认识，接下来的RBM-CF的原理就很好理解了。<a href="http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf" target="_blank" rel="noopener">Restricted Boltzmann Machines in Python</a>是Hinton大牛在2007ICML上提出的,在netfext上也取得了不错的效果。下面就详细的介绍一下算法。<br><img src="http://img.blog.csdn.net/20160924172416013" alt="image"><br>如图所示，RBM-CF是一个标准的RBM。其中V是用户对电影的评分（如图是5个级别）.可见层为用户对电影的评分向量，隐层为隐向量。</p><h3 id="能量函数和似然函数"><a href="#能量函数和似然函数" class="headerlink" title="能量函数和似然函数"></a>能量函数和似然函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E(v,h|\theta)=-\sum_&#123;i=1&#125;^&#123;n&#125;&#123;\sum_&#123;k=1&#125;^&#123;K&#125;&#123;a_iv^k_i&#125;&#125;-\sum_&#123;j=1&#125;^&#123;m&#125;&#123;b_jh_j&#125;-\sum_&#123;i=1&#125;^&#123;n&#125;\sum_&#123;j=1&#125;^&#123;m&#125;&#123;\sum_&#123;k=1&#125;^&#123;K&#125;&#123;v^k_i&#125;W_&#123;ij&#125;h_j&#125;+\sum_&#123;i=1&#125;^M&#123;logZ_i&#125;</span><br></pre></td></tr></table></figure><p>其中，\(Z<em>i=\sum^k</em>{l=1}{exp(b_i^l+\sum_j{h<em>jWw</em>{ij}})}$`<br>对应的似然函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v|\theta) = -\frac&#123;1&#125;&#123;Z(\theta)&#125;\sum_h&#123;e^&#123;-&#123;E(v,h|\theta)&#125;&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>有了以上的定义，可以获得隐层和可见层的分布：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v_i^k=1|h,\theta) = \frac&#123;exp(a_i^k+\sum_j&#123;h_j W_&#123;ij&#125;^k&#125;)&#125;&#123;\sum_&#123;l=1&#125;^Kexp(a_i^l+\sum_j&#123;h_j W_&#123;ij&#125;^l&#125;)&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(h_j=1|v,\theta) = \sigma(b_j+\sum_&#123;i=1&#125;^m&#123;\sum_&#123;k=1&#125;^K&#123;v_i W_&#123;ij&#125;^k&#125;)&#125;</span><br></pre></td></tr></table></figure><h3 id="Conditional-RBM’s"><a href="#Conditional-RBM’s" class="headerlink" title="Conditional RBM’s"></a>Conditional RBM’s</h3><p>其实在NetFlix的数据中，用户对电影的评分是比较稀疏。有大量的用户观看了电影没有评分，因此作者为了将此类信息加入到模型中，增加模型对用户评分的准确性。如图，将用户的观看列表信息加入到隐层中。<br><img src="http://img.blog.csdn.net/20160924172457545" alt="image"><br>原先每个隐层的分布变为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(h_j=1|v,\theta) = \sigma(b_j+\sum_&#123;i=1&#125;^m&#123;\sum_&#123;k=1&#125;^K&#123;v_i W_&#123;ij&#125;^k&#125;)+\sum_&#123;i=1&#125;^M&#123;r_iD_&#123;ij&#125;&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>由于参数D与可见层无关，可以作为和b偏置一样的功能，参数更新也一样。</p><h2 id="NADE"><a href="#NADE" class="headerlink" title="NADE"></a>NADE</h2><p>NADE是Hugo Larochelle在2011年提出，论文<a href="http://www.jmlr.org/proceedings/papers/v15/larochelle11a/larochelle11a.pdf" target="_blank" rel="noopener">The Neural Autoregressive Distribution Estimator</a>。具体引入NADE的原因还不是特别懂，看论文<br><code>We describe a new approach for modeling the distribution of high-dimensional vectors of discrete variables. This model is inspired by the restricted Boltzmann machine (RBM), which has been shown to be a powerful model of such distributions. However, an RBM typically does not provide a tractable distribution estimator, since evaluating the probability it assigns to some given observation requires the computation of the so-called partition function, which itself is intractable for RBMs of even moderate size.</code></p><h3 id="可见层分布"><a href="#可见层分布" class="headerlink" title="可见层分布"></a>可见层分布</h3><p>将RBM贝叶斯网络化，v为可见层节点，\(v_{parent(i)}$`可以理解为\(v_i\)的网络中的隐层节点。那么可见层的分布为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v)=\prod^D_i&#123;p(v_i|v_&#123;parents(i)&#125;)&#125;</span><br></pre></td></tr></table></figure></p><p>现在有两种表征\(p(v<em>i|v</em>{parents(i)})$`的方式，分别为FVSBM和NADE.<br><img src="http://img.blog.csdn.net/20160925113216371" alt="image"></p><h4 id="FVSBM"><a href="#FVSBM" class="headerlink" title="FVSBM"></a>FVSBM</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v_i|v_&#123;parents(i)&#125;)=sigm(b_i+\sum_&#123;j&lt;i&#125;&#123;W_&#123;ij&#125;v_j&#125;)</span><br></pre></td></tr></table></figure><h4 id="NADE-1"><a href="#NADE-1" class="headerlink" title="NADE"></a>NADE</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(v_i=1|v_&#123;&lt;i&#125;)=sigm(b_i+&#123;(W^T)_&#123;i&#125;.h_i&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h_i=sigm(c+&#123;W,_&#123;&lt;i&#125;v_&#123;&lt;i&#125;&#125;)</span><br></pre></td></tr></table></figure><p>以上是NADE的可见层的分布公式，下面是求解流程：</p><ul><li>#计算p(v)</li><li>a=c</li><li>p(v)=0</li><li>For i=1,2,…,D:<ul><li>\(h_i=sigm(a)$`</li><li>\(p(v<em>i=1|v</em>{&lt;i})=simg(b_i+V_i.h_i)$`</li><li>\(p(v)=p(v)(p(v<em>i=1|v</em>{&lt;i})^{v_i} + (1-p(v<em>i=1|v</em>{&lt;i})^{1-v_i}))$`</li><li>\(a=a+W.,_iv_i\)</li></ul></li><li>EndFor</li><li></li><li>计算梯度-log(p(v))</li><li>`${\delta{a}}=0\)</li><li>`${\delta{c}}=0\)</li><li>For i,2,…,D:<ul><li>`${\delta{b_i}}=p(v<em>i=1|v</em>{&lt;i}) - v_i\)</li><li>`${\delta{V_i}}=(p(v<em>i=1|v</em>{&lt;i}) - v_i)h^T_i\)</li><li>`${\delta{h_i}}=(p(v<em>i=1|v</em>{&lt;i}) - v_i)V^T_i\)</li><li><code>${\delta{c}}=\delta{c}+(\delta{h_i})h_i(1-h_i)$</code></li><li>`$\delta{W,_i} = (\delta{a})v_i\)</li><li><code>${\delta{a}}=\delta{a}+(\delta{h_i})h_i(1-h_i)$</code></li></ul></li><li>EndFor</li><li>参数更新<h2 id="NADE-CF"><a href="#NADE-CF" class="headerlink" title="NADE-CF"></a>NADE-CF</h2>在以上铺垫后，就是讲应用加入到模型就行了。先定义一些参数\(r^u={r^u<em>{m</em>{o1}},r^u<em>{m</em>{o2}},..,r^u<em>{m</em>{oD}}}$<code>为用户的评分序列，\\(r^u_{m_{oi}}$</code>为用户的评分，在1-k之间。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(r)=\prod^D_&#123;i=1&#125;&#123;p(r_&#123;m_&#123;oi&#125;&#125; | r_&#123;m_&#123;o&lt;i&#125;&#125;)&#125;</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h(r_&#123;m_&#123;o&lt;i&#125;&#125;)=g(c+\sum_&#123;j&lt;i&#125;W^&#123;r_&#123;m_&#123;oj&#125;&#125;&#125;_&#123;m_&#123;oj&#125;&#125;)</span><br></pre></td></tr></table></figure><p>另外，若写成每个用户对每个电影在评分K上的分布：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p(r_&#123;m_&#123;oi&#125;&#125;=k|r_&#123;m_&#123;o&lt;i&#125;&#125;) = \frac&#123;exp(s^k_&#123;m_&#123;oi&#125;&#125;(r_&#123;m_&#123;o&lt;i&#125;&#125;))&#125;&#123;\sum^K_q&#123;exp(s^q_&#123;m_&#123;oi&#125;&#125;(r_&#123;m_&#123;o&lt;i&#125;&#125;))&#125;&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s^k_&#123;m_&#123;oi&#125;&#125;(r_&#123;m_&#123;o&lt;i&#125;&#125;) = b^k_&#123;m_&#123;oi&#125;&#125; + V^k_&#123;m_&#123;oi&#125;&#125;h(r_&#123;m_&#123;o&lt;i&#125;&#125;)</span><br></pre></td></tr></table></figure><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-logp(r) = -\sum^D_i&#123;logp(r_&#123;m_&#123;oi&#125;&#125;|r_&#123;m_&#123;o&lt;i&#125;&#125;&#125;)</span><br></pre></td></tr></table></figure><h3 id="参数共享"><a href="#参数共享" class="headerlink" title="参数共享"></a>参数共享</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h(r_&#123;m_&#123;o&lt;i&#125;&#125;)=g(c+\sum_&#123;j&lt;i&#125;&#123;\sum^&#123;r_&#123;m_&#123;oj&#125;&#125;&#125;_kW^&#123;k&#125;_&#123;m_&#123;oj&#125;&#125;&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s^k_&#123;m_&#123;oi&#125;&#125;(r_&#123;m_&#123;o&lt;i&#125;&#125;) = \sum_&#123;j&lt;k&#125;&#123;b^k_&#123;m_&#123;oi&#125;&#125; + V^k_&#123;m_&#123;oi&#125;&#125;h(r_&#123;m_&#123;o&lt;i&#125;&#125;)&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;RBM-and-NADE-TO-Collaborative-Filtering&quot;&gt;&lt;a href=&quot;#RBM-and-NADE-TO-Collaborative-Filtering&quot; class=&quot;headerlink&quot; title=&quot;RBM and NADE T
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://leaveslr.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文" scheme="https://leaveslr.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>hexo+next 博客系统搭建</title>
    <link href="https://leaveslr.github.io/2018/02/02/hexo-next-%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/"/>
    <id>https://leaveslr.github.io/2018/02/02/hexo-next-博客系统搭建/</id>
    <published>2018-02-02T08:36:35.000Z</published>
    <updated>2018-02-03T05:29:54.152Z</updated>
    
    <content type="html"><![CDATA[<p>自己搭建博客的一些参考资料，记录防止以后用到。并非教程。<br><a id="more"></a></p><h2 id="博客的搭建"><a href="#博客的搭建" class="headerlink" title="博客的搭建"></a>博客的搭建</h2><h2 id="博客的个性化设置"><a href="#博客的个性化设置" class="headerlink" title="博客的个性化设置"></a>博客的个性化设置</h2><h3 id="文章阅读次数"><a href="#文章阅读次数" class="headerlink" title="文章阅读次数"></a>文章阅读次数</h3><p>本博客的阅读次数统计使用的是leanCloud账号，注册相对简单，具体步骤：</p><ol><li>创建LeanCloud账号<a href="https://leancloud.cn/" target="_blank" rel="noopener">LeanCloud</a></li><li>创建应用：注册并登录LeanCloud后，进入控制台，单击“创建应用”按钮进行应用的创建，输入新应用名称，选择开发版，单击“创建”按钮完成创建。  <img src="https://upload-images.jianshu.io/upload_images/291600-a114303ec633d628.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt=""></li><li><p>创建Class:进入到刚刚创建的应用中，选择左侧导航栏的“存储”，然后点击“创建Class”，为了与NexT形成配置关系，将Class名称填为Counter，并选择无限制选项，然后单击“创建Class”按钮完成Class的创建，如下图所示：<img src="https://upload-images.jianshu.io/upload_images/291600-47b6f370eeb9384f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt=""></p><p> 点击刚刚创建的Counter，其实质是一张结构表，用来记录文章的浏览量，如下图所示，这里的表可以直接对文章阅读次数进行修改，所以如果想要追求阅读次数的读者可以在表上直接进行修改。</p></li><li><p>配置key:在左侧导航栏的设置界面，单击“应用Key”可以看到应用的App ID和App Key。复制ID和Key，然后将其配置到主题配置文件中，在文件中找到leancloud_visitors属性，将enable设置为true，然后将之前复制的ID和Key粘贴到相应的属性中。</p></li></ol><h3 id="分享"><a href="#分享" class="headerlink" title="分享"></a>分享</h3><p>一开始用的 JiaThis, 后发现发不上去就不显示。后使用的needmoreshare2。</p><pre><code># NeedMoreShare2# This plugin is a pure javascript sharing lib which is useful in China.# See: https://github.com/revir/need-more-share2# Also see: https://github.com/DzmVasileusky/needShareButton# iconStyle: default | box# boxForm: horizontal | vertical# position: top / middle / bottom + Left / Center / Right# networks: Weibo,Wechat,Douban,QQZone,Twitter,Linkedin,Mailto,Reddit,#           Delicious,StumbleUpon,Pinterest,Facebook,GooglePlus,Slashdot,#           Technorati,Posterous,Tumblr,GoogleBookmarks,Newsvine,#           Evernote,Friendfeed,Vkontakte,Odnoklassniki,Mailruneedmoreshare2:  enable: true  postbottom:    enable: true    options:      iconStyle: default      boxForm: horizontal      position: bottomCenter      networks: Weibo,Wechat,Douban,QQZone,Twitter,Facebook float:    enable: false    options:      iconStyle: box      boxForm: horizontal</code></pre><h3 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h3><p>一开始折腾了使用 <a href="http://www.uyan.cc/" target="_blank" rel="noopener">友言</a>,发现一直出不来效果，就果断放弃了（后期看看加入好的评论系统）。然后转向了简单的<a href="https://valine.js.org/" target="_blank" rel="noopener">Valine</a>.</p><p>Valine一款快速、简洁且高效的无后端评论系统,基于Leancloud开发。具体流程：</p><ol><li>创建LeanCloud账号<a href="https://leancloud.cn/" target="_blank" rel="noopener">LeanCloud</a> 并获取 App ID和App Key。</li><li><p>配置：</p><p>  # Valine.<br>  # You can get your appid and appkey from <a href="https://leancloud.cn" target="_blank" rel="noopener">https://leancloud.cn</a><br>  # more info please open <a href="https://valine.js.org" target="_blank" rel="noopener">https://valine.js.org</a><br>  valine:</p><pre><code>enable: trueappid: *****appkey: ****notify: false # mail notifier , https://github.com/xCss/Valine/wikiverify: false # Verification codeplaceholder: Just go go # comment box placeholderavatar: mm # gravatar styleguest_info: nick,mail,link # custom comment headerpageSize: 10 # pagination size </code></pre></li></ol><h3 id="布局大小调整"><a href="#布局大小调整" class="headerlink" title="布局大小调整"></a>布局大小调整</h3><p>一开始用的next默认的布局，但是看到<a href="http://jmyblog.top" target="_blank" rel="noopener">jmyblog</a>后，发现自己的布局可以调整，就尝试调整了一下，在官方文章中设置内容区域布局：NexT 对于内容的宽度的设定如下：700px，当屏幕宽度 &lt; 1600px；900px，当屏幕宽度 &gt;= 1600px；移动设备下，宽度自适应。</p><p>如果你需要修改内容的宽度，同样需要编辑样式文件。 编辑主题的 source/css/_variables/custom.styl 文件，新增变量：<br>    // 修改成你期望的宽度<br>    $content-desktop = 700px</p><pre><code>// 当视窗超过 1600px 后的宽度$content-desktop-large = 900px</code></pre><p>但是对于Pisces Scheme，需要单独配置source/css/_variables/custom.styl：</p><pre><code>.header{ width: 90%; }.container .main-inner { width: 90%; }.content-wrap { width: calc(100% - 260px); }</code></pre><h3 id="侧边栏调整"><a href="#侧边栏调整" class="headerlink" title="侧边栏调整"></a>侧边栏调整</h3><h3 id="文末版权信息"><a href="#文末版权信息" class="headerlink" title="文末版权信息"></a>文末版权信息</h3><h3 id="站点访问人数"><a href="#站点访问人数" class="headerlink" title="站点访问人数"></a>站点访问人数</h3><p>具体实现方法，在\themes\next\layout_partials\footer.swig文件中，在copyright前加以下代码：</p><pre><code>&lt;script async src=&quot;https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;</code></pre><p>在再合适的位置添加显示统计的代码：</p><pre><code>&lt;div class=&quot;powered-by&quot;&gt;&lt;i class=&quot;fa fa-user-md&quot;&gt;&lt;/i&gt;&lt;span id=&quot;busuanzi_container_site_uv&quot;&gt;  访客:&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;  浏览:&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;  &lt;/span&gt;&lt;/div&gt;</code></pre><h3 id="文章字数统计"><a href="#文章字数统计" class="headerlink" title="文章字数统计"></a>文章字数统计</h3><ol><li>切换到根目录下，然后运行如下代码 <code>$ npm install hexo-wordcount --save</code></li><li><p>然后在主题的配置文件中，配置如下：</p><p> `# Post wordcount display settings</p><h1 id="Dependencies-https-github-com-willin-hexo-wordcount"><a href="#Dependencies-https-github-com-willin-hexo-wordcount" class="headerlink" title="Dependencies: https://github.com/willin/hexo-wordcount"></a>Dependencies: <a href="https://github.com/willin/hexo-wordcount" target="_blank" rel="noopener">https://github.com/willin/hexo-wordcount</a></h1><p>  post_wordcount:<br>  item_text: true<br>  wordcount: true<br>  min2read: true`</p></li></ol><h3 id="修改文章底部的那个带-号的标签"><a href="#修改文章底部的那个带-号的标签" class="headerlink" title="修改文章底部的那个带#号的标签"></a>修改文章底部的那个带#号的标签</h3><p>修改模板/themes/next/layout/_macro/post.swig，搜索<br> <code>rel=&quot;tag&quot;&gt;#，将 # 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;</code></p><h3 id="网站底部次数统计"><a href="#网站底部次数统计" class="headerlink" title="网站底部次数统计"></a>网站底部次数统计</h3><p>需要使用hexo-wordcount 具体步骤：</p><ol><li>切换到根目录下，然后运行如下代码 <code>$ npm install hexo-wordcount --save</code></li><li>然后在/themes/next/layout/_partials/footer.swig文件尾部加上：</li></ol><h3 id="加入百度"><a href="#加入百度" class="headerlink" title="加入百度"></a>加入百度</h3><h2 id="hexo-next-资料"><a href="#hexo-next-资料" class="headerlink" title="hexo+next 资料"></a>hexo+next 资料</h2><ol><li>next官方： <a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">http://theme-next.iissnan.com/</a></li><li>hexo的next主题个性化教程：打造炫酷网站 <a href="http://blog.csdn.net/qq_33699981/article/details/72716951" target="_blank" rel="noopener">http://blog.csdn.net/qq_33699981/article/details/72716951</a></li><li>一个好的布局：<a href="http://jmyblog.top/" target="_blank" rel="noopener">http://jmyblog.top/</a></li><li>布局优化：<a href="http://blog.csdn.net/heqiangflytosky/article/details/54863185" target="_blank" rel="noopener">http://blog.csdn.net/heqiangflytosky/article/details/54863185</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;自己搭建博客的一些参考资料，记录防止以后用到。并非教程。&lt;br&gt;
    
    </summary>
    
    
      <category term="个人" scheme="https://leaveslr.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>hello word</title>
    <link href="https://leaveslr.github.io/2018/02/02/hello-word/"/>
    <id>https://leaveslr.github.io/2018/02/02/hello-word/</id>
    <published>2018-02-02T07:01:51.000Z</published>
    <updated>2018-02-03T14:01:45.753Z</updated>
    
    <content type="html"><![CDATA[<p>This is a summary of the post.<br><a id="more"></a></p><pre><code>$$\frac{7x+5}{1+y^2}$$</code></pre><p>##Say you have a lenghty post and don’t like the fact that the entire article is displayed in the listing pages…<br>You can mark a spot in your markdown with <!-- more --> to hide it from the listing pages. It will be replaced with a “Read more” link that will open the rest of the article content.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is a summary of the post.&lt;br&gt;
    
    </summary>
    
      <category term="个人" scheme="https://leaveslr.github.io/categories/%E4%B8%AA%E4%BA%BA/"/>
    
    
      <category term="个人" scheme="https://leaveslr.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
</feed>
